# Document Processing — индексация и подготовка текстовых данных

## Назначение
Document Processing отвечает за асинхронную обработку загруженных документов: извлечение текста, разбиение на логические фрагменты и подготовку векторных представлений для последующего поиска релевантного контента.

## Технологический стек
- **Язык**: Go 1.24
- **Очереди**: RabbitMQ
- **Хранилище файлов**: S3
- **Векторная БД**: OpenSearch
- **Embeddings**: OpenAI API (text-embedding-3-small)
- **API**: gRPC + gRPC Gateway
- **Парсинг**: ledongthuc/pdf, custom TXT parser
- **Логирование**: zap
- **Трейсинг**: Jaeger
- **Контейнеризация**: Docker + Docker Compose

## Структура проекта
```
doc-processing/
├── api/               # Protocol Buffers определения
│   └── document/
│       └── document.proto
├── cmd/               # Точки входа приложения
│   ├── doc-processor/ # gRPC сервер для поиска
│   │   └── main.go
│   └── worker/        # Воркер обработки документов
│       └── main.go
├── internal/
│   ├── app/           # Инициализация приложения
│   │   ├── api/       # gRPC handlers
│   │   └── app.go
│   ├── chunker/       # Разбиение текста на фрагменты
│   ├── config/        # Конфигурация
│   ├── domain/        # Доменные модели
│   ├── embeddings/    # Клиент для генерации embeddings
│   ├── logger/        # Логирование
│   ├── parser/        # Парсеры документов (PDF, TXT)
│   ├── queue/         # RabbitMQ клиент
│   ├── service/       # Бизнес-логика
│   ├── storage/       # S3 клиент
│   ├── tracer/        # Jaeger трейсинг
│   └── vectordb/      # OpenSearch клиент
├── pkg/               # Сгенерированный код из proto
├── config.yaml        # Конфигурация для локальной разработки
├── config.docker.yaml # Конфигурация для Docker
├── compose.yaml       # Docker Compose конфигурация
├── Dockerfile         # Образ Docker
└── Makefile          # Команды сборки и генерации
```

## Зона ответственности
- Получение задач на обработку документов из очереди RabbitMQ
- Чтение исходного файла из S3 хранилища
- Извлечение текстового содержимого из PDF / DOCX / TXT
- Разбиение текста на чанки с перекрытием для контекста
- Генерация векторных представлений (embeddings) через OpenAI API
- Индексация фрагментов в OpenSearch
- Предоставление gRPC API для поиска релевантных фрагментов

## Компоненты

### 1. Document Processor Worker
Асинхронный обработчик документов:
- Подписывается на очередь RabbitMQ
- Извлекает текст из документов
- Генерирует чанки с метаданными
- Создает embeddings батчами
- Индексирует в OpenSearch

### 2. gRPC API Server
Предоставляет API для поиска:
- `SearchChunks` - векторный поиск по документам организации
- HTTP Gateway на порту 8081
- Метрики Prometheus на `/metrics`

## Контракт события обработки документа

Сервис читает задания из очереди RabbitMQ и ожидает сообщения в формате JSON.

- Очередь: `document_processing` (см. `rabbitmq.queue_name` в `config.yaml`)
- Content-Type: `application/json`
- Кодировка: UTF-8

Поля события:
- `DocumentID` — строковый идентификатор документа (рекомендуется UUID)
- `OrganizationID` — строковый идентификатор организации (рекомендуется UUID)
- `S3Key` — ключ файла в S3 (может содержать Unicode и пробелы)
- `DocumentType` — тип документа: `pdf` | `docx` | `txt`
- `DocumentName` — отображаемое имя файла (оригинальное имя)

Пример сообщения:

```json
{
	"DocumentID": "doc-123",
	"OrganizationID": "org-456",
	"S3Key": "Даньшин Семён.pdf",
	"DocumentType": "pdf",
	"DocumentName": "Даньшин Семён.pdf"
}
```

Примечания:
- Дополнительные внутренние поля (`RetryCount`, `MaxRetries`, `CreatedAt`) могут быть добавлены обработчиком и не требуются от отправителя.
- `S3Key` должен ссылаться на уже загруженный объект в указанном бакете (см. раздел `s3` в конфигурации).
- Для больших файлов рекомендуется загружать в S3 заранее и публиковать событие только после успешной загрузки.
